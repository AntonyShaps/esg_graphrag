{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88640c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "# Ollama OpenAI-compatible endpoint\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key=\"ollama\",\n",
    ")\n",
    "\n",
    "def chat(messages, model, temperature=0, **config):\n",
    "    \"\"\"Generic chat call, returns full message object.\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        messages=messages,\n",
    "        **config,\n",
    "    )\n",
    "    return response.choices[0].message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1680aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"select_graph\",\n",
    "            \"description\": \"Select which company graph DB (meta, google, or nvidia) is most relevant to answer the question.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"graph\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The selected graph database.\",\n",
    "                        \"enum\": [\"meta\", \"google\", \"nvidia\"]\n",
    "                    },\n",
    "                    \"confidence\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"Confidence between 0 and 1 that this is the right graph.\",\n",
    "                    },\n",
    "                    \"reason\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Short explanation of why this graph was selected.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"graph\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997ab245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_to_graph(question: str, model: str = \"mistral:latest\") -> dict:\n",
    "    \"\"\"\n",
    "    Uses function calling to choose which graph db to query.\n",
    "    Returns dict like: {\"graph\": \"meta\", \"confidence\": 0.93, \"reason\": \"...\"}\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a router. Your job is to choose which company's knowledge graph \"\n",
    "                \"should be queried to answer the user's question. \"\n",
    "                \"Options: meta, google, nvidia.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Decide which graph to use for this question: '{question}'\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        tools=router_tools,\n",
    "        tool_choice=\"auto\",\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    message = response.choices[0].message\n",
    "\n",
    "    if not message.tool_calls:\n",
    "        # Fallback: guess \"meta\" if nothing is returned\n",
    "        return {\"graph\": \"meta\", \"confidence\": 0.5, \"reason\": \"No tool call, defaulting to meta.\"}\n",
    "\n",
    "    tool_call = message.tool_calls[0]\n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "    # Ensure defaults\n",
    "    return {\n",
    "        \"graph\": args.get(\"graph\", \"meta\"),\n",
    "        \"confidence\": float(args.get(\"confidence\", 0.5)),\n",
    "        \"reason\": args.get(\"reason\", \"\"),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d98208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import numpy as np\n",
    "# from sentence_transformers import SentenceTransformer  # example\n",
    "\n",
    "# driver = GraphDatabase.driver(\"neo4j://localhost:7687\", auth=(\"neo4j\", \"graphgraph\"))\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # example\n",
    "\n",
    "def retrieve_from_meta(question: str, k: int = 4) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Retrieve top-k similar chunks from the Meta Neo4j graph using vector index 'pdf'.\n",
    "    Returns list of dicts with keys: text, score, index.\n",
    "    \"\"\"\n",
    "    question_embedding = embed_model.encode([question])[0].tolist()\n",
    "\n",
    "    cypher = \"\"\"\n",
    "    CALL db.index.vector.queryNodes('pdf', $k, $question_embedding) \n",
    "    YIELD node AS hits, score\n",
    "    RETURN hits.text AS text, score, hits.index AS index\n",
    "    \"\"\"\n",
    "\n",
    "    records, _, _ = driver.execute_query(\n",
    "        cypher,\n",
    "        question_embedding=question_embedding,\n",
    "        k=k,\n",
    "        database_=\"neo4j\",  # or your db name\n",
    "    )\n",
    "\n",
    "    # Convert from Neo4j record objects to plain dicts\n",
    "    return [\n",
    "        {\"text\": r[\"text\"], \"score\": r[\"score\"], \"index\": r[\"index\"]}\n",
    "        for r in records\n",
    "    ]\n",
    "\n",
    "\n",
    "def retrieve_from_google(question: str, k: int = 4) -> list[dict]:\n",
    "    # Placeholder for future Google KG implementation\n",
    "    raise NotImplementedError(\"Google graph retriever not implemented yet.\")\n",
    "\n",
    "\n",
    "def retrieve_from_nvidia(question: str, k: int = 4) -> list[dict]:\n",
    "    # Placeholder for future NVIDIA KG implementation\n",
    "    raise NotImplementedError(\"NVIDIA graph retriever not implemented yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba15949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_docs(question: str, graph_choice: str, k: int = 4) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Dispatch to the appropriate retriever based on graph_choice.\n",
    "    \"\"\"\n",
    "    if graph_choice == \"meta\":\n",
    "        return retrieve_from_meta(question, k=k)\n",
    "    elif graph_choice == \"google\":\n",
    "        return retrieve_from_google(question, k=k)\n",
    "    elif graph_choice == \"nvidia\":\n",
    "        return retrieve_from_nvidia(question, k=k)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown graph choice: {graph_choice}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128175cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANSWER_SYSTEM_PROMPT = \"\"\"\n",
    "You're a company ESG expert. \n",
    "You can only use the provided documents to answer the user's question.\n",
    "If the answer is not present or not fully specified in the documents, say: \"I don't know based on these documents.\"\n",
    "You may see HTML structures (tables); interpret them as data.\n",
    "\"\"\"\n",
    "\n",
    "def answer_with_docs(question: str, docs: list[dict], model: str = \"mistral:latest\") -> str:\n",
    "    docs_text = [doc[\"text\"] for doc in docs]\n",
    "\n",
    "    user_message = f\"\"\"\n",
    "Use the following documents to answer the question.\n",
    "Only use information from these documents; if you don't know, say you don't know.\n",
    "\n",
    "Documents:\n",
    "{docs_text}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "    msg = chat(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": ANSWER_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_message},\n",
    "        ],\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return msg.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c63af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(question: str) -> str:\n",
    "\n",
    "    # 2) Route to the right graph\n",
    "    routing = route_to_graph(question, model=\"mistral:latest\")\n",
    "    graph_choice = routing[\"graph\"]\n",
    "\n",
    "    print(f\"[ROUTER] Chosen graph: {graph_choice} (conf={routing['confidence']:.2f})\")\n",
    "    if routing[\"reason\"]:\n",
    "        print(f\"[ROUTER REASON] {routing['reason']}\")\n",
    "\n",
    "    # 3) Retrieve docs (for now only meta works)\n",
    "    docs = retrieve_docs(question, graph_choice, k=4)\n",
    "\n",
    "    if not docs:\n",
    "        return \"I couldn't find any relevant documents in the selected graph.\"\n",
    "\n",
    "    # 4) Answer using Mistral based only on retrieved docs\n",
    "    final_answer = answer_with_docs(question, docs, model=\"mistral:latest\")\n",
    "    return final_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8481dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(main(\"meta scope 1 emissions\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
